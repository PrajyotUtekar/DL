{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535110a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de45ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Preparation\n",
    "sentences = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ce75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "sentences = re.sub('[^A-Za-z0-9]+', ' ', sentences)  # Remove special characters\n",
    "sentences = re.sub(r'(?:^| )\\w(?:$| )', ' ', sentences).strip()  # Remove 1-letter words\n",
    "sentences = sentences.lower()  # Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6f0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary\n",
    "words = sentences.split()\n",
    "vocab = set(words)\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 10\n",
    "context_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53597f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for i, word in enumerate(vocab)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64b6692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['we', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'computational'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "# Data Bags\n",
    "data = []\n",
    "for i in range(2, len(words) - 2):\n",
    "    context = [words[i - 2], words[i - 1], words[i + 1], words[i + 2]]\n",
    "    target = words[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "054811fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "embeddings = np.random.random_sample((vocab_size, embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12952e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model\n",
    "def linear(m, theta):\n",
    "    w = theta\n",
    "    return m.dot(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27816de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log softmax + NLL loss = Cross Entropy\n",
    "def log_softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return np.log(e_x / e_x.sum())\n",
    "\n",
    "def NLLLoss(logs, targets):\n",
    "    out = logs[range(len(targets)), targets]\n",
    "    return -out.sum() / len(out)\n",
    "\n",
    "def log_softmax_crossentropy_with_logits(logits, target):\n",
    "    out = np.zeros_like(logits)\n",
    "    out[np.arange(len(logits)), target] = 1\n",
    "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1, keepdims=True)\n",
    "    return (-out + softmax) / logits.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b31bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Function\n",
    "def forward(context_idxs, theta):\n",
    "    m = embeddings[context_idxs].reshape(1, -1)\n",
    "    n = linear(m, theta)\n",
    "    o = log_softmax(n)\n",
    "    return m, n, o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408cabf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Function\n",
    "def backward(preds, theta, target_idxs):\n",
    "    m, n, o = preds\n",
    "    dlog = log_softmax_crossentropy_with_logits(n, target_idxs)\n",
    "    dw = m.T.dot(dlog)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e7a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize Function\n",
    "def optimize(theta, grad, lr=0.03):\n",
    "    theta -= grad * lr\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ccfa9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training Data\n",
    "theta = np.random.uniform(-1, 1, (2 * context_size * embed_dim, vocab_size))\n",
    "epoch_losses = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92672e32",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (1768814587.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\lang lab\\AppData\\Local\\Temp\\ipykernel_11000\\1768814587.py\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    target_idxs = np.array([word_to_ix[target])\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(80):\n",
    "    losses = []\n",
    "    for context, target in data:\n",
    "        context_idxs = np.array([word_to_ix[w] for w in context])\n",
    "        preds = forward(context_idxs, theta)\n",
    "        target_idxs = np.array([word_to_ix[target])\n",
    "        loss = NLLLoss(preds[-1], target_idxs)\n",
    "        losses.append(loss)\n",
    "        grad = backward(preds, theta, target_idxs)\n",
    "        theta = optimize(theta, grad, lr=0.03)\n",
    "    epoch_losses[epoch] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89092d74",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11000\\1637582092.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch/Losses'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mepoch_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Losses'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11000\\1637582092.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch/Losses'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mepoch_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Losses'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Losses vs. Epochs\n",
    "ix = np.arange(0, 80)\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Epoch/Losses', fontsize=20)\n",
    "plt.plot(ix, [epoch_losses[i][0] for i in ix])\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Losses', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabfb45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
